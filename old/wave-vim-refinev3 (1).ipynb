{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12823653,"sourceType":"datasetVersion","datasetId":8109412},{"sourceId":12824883,"sourceType":"datasetVersion","datasetId":8110346},{"sourceId":12839595,"sourceType":"datasetVersion","datasetId":8120578},{"sourceId":12839661,"sourceType":"datasetVersion","datasetId":8120625}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd /kaggle/working\nwith open(\"/kaggle/input/token-main/token_main.txt\", \"r\") as f:\n    TOKEN = f.read().strip()\n\nGITHUB_USER = \"mintesnot96\"\nREPO_NAME = \"wave-vim-refinev3\"\n\n!rm -rf /kaggle/working/wave-vim-refinev3\n!git clone https://{GITHUB_USER}:{TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:22:33.125217Z","iopub.execute_input":"2025-08-23T09:22:33.125895Z","iopub.status.idle":"2025-08-23T09:22:34.198164Z","shell.execute_reply.started":"2025-08-23T09:22:33.125868Z","shell.execute_reply":"2025-08-23T09:22:34.197254Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'wave-vim-refinev3'...\nremote: Enumerating objects: 139, done.\u001b[K\nremote: Counting objects: 100% (139/139), done.\u001b[K\nremote: Compressing objects: 100% (97/97), done.\u001b[K\nremote: Total 139 (delta 60), reused 110 (delta 34), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (139/139), 116.36 KiB | 7.27 MiB/s, done.\nResolving deltas: 100% (60/60), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# install requirements","metadata":{}},{"cell_type":"code","source":"!pip install -r /kaggle/working/wave-vim-refinev3/requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:22:34.199906Z","iopub.execute_input":"2025-08-23T09:22:34.200601Z","iopub.status.idle":"2025-08-23T09:23:52.552999Z","shell.execute_reply.started":"2025-08-23T09:22:34.200574Z","shell.execute_reply":"2025-08-23T09:23:52.552257Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4)) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/wave-vim-refinev3/requirements.txt (line 5)) (0.21.0+cu124)\nRequirement already satisfied: torchaudio>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/wave-vim-refinev3/requirements.txt (line 6)) (2.6.0+cu124)\nRequirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/wave-vim-refinev3/requirements.txt (line 7)) (0.8.1)\nRequirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/wave-vim-refinev3/requirements.txt (line 8)) (4.67.1)\nRequirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/wave-vim-refinev3/requirements.txt (line 9)) (6.0.2)\nRequirement already satisfied: opencv-python>=4.8.1 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/wave-vim-refinev3/requirements.txt (line 10)) (4.11.0.86)\nRequirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/wave-vim-refinev3/requirements.txt (line 11)) (1.26.4)\nRequirement already satisfied: Pillow>=10.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/wave-vim-refinev3/requirements.txt (line 12)) (11.2.1)\nRequirement already satisfied: scikit-image>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/wave-vim-refinev3/requirements.txt (line 13)) (0.25.2)\nCollecting lpips>=0.1.4 (from -r /kaggle/working/wave-vim-refinev3/requirements.txt (line 14))\n  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\nCollecting open_clip_torch>=2.24.0 (from -r /kaggle/working/wave-vim-refinev3/requirements.txt (line 16))\n  Downloading open_clip_torch-3.1.0-py3-none-any.whl.metadata (32 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4)) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4)) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4)) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4)) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4)) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4))\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4))\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4))\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4))\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4))\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4))\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4))\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4))\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4))\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4)) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4)) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4)) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4))\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4)) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4)) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 11)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 11)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 11)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 11)) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 11)) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 11)) (2.4.1)\nRequirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.22.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 13)) (1.15.3)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.22.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 13)) (2.37.0)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.22.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 13)) (2025.6.11)\nRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.22.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 13)) (25.0)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.22.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 13)) (0.4)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from open_clip_torch>=2.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 16)) (2024.11.6)\nCollecting ftfy (from open_clip_torch>=2.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 16))\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from open_clip_torch>=2.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 16)) (0.33.1)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from open_clip_torch>=2.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 16)) (0.5.3)\nCollecting timm>=1.0.17 (from open_clip_torch>=2.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 16))\n  Downloading timm-1.0.19-py3-none-any.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open_clip_torch>=2.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 16)) (0.2.13)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch>=2.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 16)) (2.32.4)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch>=2.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 16)) (1.1.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 4)) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 11)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 11)) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 11)) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 11)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 11)) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch>=2.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 16)) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch>=2.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 16)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch>=2.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 16)) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch>=2.24.0->-r /kaggle/working/wave-vim-refinev3/requirements.txt (line 16)) (2025.6.15)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading lpips-0.1.4-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading open_clip_torch-3.1.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading timm-1.0.19-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm, open_clip_torch, lpips\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: timm\n    Found existing installation: timm 1.0.15\n    Uninstalling timm-1.0.15:\n      Successfully uninstalled timm-1.0.15\nSuccessfully installed ftfy-6.3.1 lpips-0.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 open_clip_torch-3.1.0 timm-1.0.19\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport yaml\n\n# Path to project\nPROJ = \"/kaggle/working/wave-vim-refinev3\"\n\n# Path to YAML\ncfg_path = os.path.join(PROJ, \"configs\", \"default.yaml\")\n\n# Load YAML\nwith open(cfg_path, \"r\") as f:\n    cfg = yaml.safe_load(f)\n\n# Base path to your test dataset\nval_base = os.path.join(PROJ, \"/kaggle/input/cdd-11/CDD-11_test\")\n\n# List all subfolders (exclude 'clear')\ndegradations = [d for d in os.listdir(val_base) if os.path.isdir(os.path.join(val_base, d)) and d != \"clear\"]\n\n# Update validation config\ncfg[\"val_data\"][\"paired_roots\"] = [val_base]  # parent folder\ncfg[\"val_data\"][\"root_clean\"] = os.path.join(val_base, \"clear\")  # clean images\ncfg[\"val_data\"][\"include_folders\"] = degradations  # all degradations\n\n# Save updated YAML\nwith open(cfg_path, \"w\") as f:\n    yaml.safe_dump(cfg, f, sort_keys=False)\n\nprint(\"Validation config updated with degradations:\", degradations)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:23:52.553982Z","iopub.execute_input":"2025-08-23T09:23:52.554279Z","iopub.status.idle":"2025-08-23T09:23:52.601003Z","shell.execute_reply.started":"2025-08-23T09:23:52.554250Z","shell.execute_reply":"2025-08-23T09:23:52.600301Z"}},"outputs":[{"name":"stdout","text":"Validation config updated with degradations: ['low_haze_snow', 'haze_rain', 'snow', 'low', 'rain', 'low_haze_rain', 'haze_snow', 'haze', 'low_rain', 'low_snow', 'low_haze']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Train from the Begninbeginning ","metadata":{}},{"cell_type":"code","source":"# !python /kaggle/working/wave-vim-refinev3/train.py \\\n#   --config /kaggle/working/wave-vim-refinev3/configs/default.yaml \\\n#   --epochs 1 --amp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:23:52.602718Z","iopub.execute_input":"2025-08-23T09:23:52.602966Z","iopub.status.idle":"2025-08-23T09:23:52.606444Z","shell.execute_reply.started":"2025-08-23T09:23:52.602946Z","shell.execute_reply":"2025-08-23T09:23:52.605725Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"PROJ = \"/kaggle/working/wave-vim-refinev3\"\n%cd $PROJ\n! python train.py --config /kaggle/working/wave-vim-refinev3/configs/default.yaml","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:23:52.607173Z","iopub.execute_input":"2025-08-23T09:23:52.607352Z","iopub.status.idle":"2025-08-23T09:24:44.191632Z","shell.execute_reply.started":"2025-08-23T09:23:52.607336Z","shell.execute_reply":"2025-08-23T09:24:44.190713Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/wave-vim-refinev3\n[DATA] train samples: 275 | val samples: 2200\n[DATA] sample shapes: x=(3, 256, 256) y=(3, 256, 256) neg=(3, 256, 256)\n[DATA] meta example: {'degradations': ['rain'], 'path': '/kaggle/input/cdd-11-30/CDD-11_train/rain/00009.png'}\n[DATA] mask shape: (1, 256, 256) | meta: {'degradations': ['rain'], 'path': '/kaggle/input/cdd-11-30/CDD-11_train/rain/00009.png'}\nopen_clip_model.safetensors: 100%|████████████| 605M/605M [00:02<00:00, 301MB/s]\n[CLIP] mem_names=13 | txt_dim=512\n[IO] outputs → /kaggle/working/outputs/dsm_wavevitmamba_tinyrefiner\n[IO] log     → /kaggle/working/outputs/dsm_wavevitmamba_tinyrefiner/train.log\n[Resume] starting from scratch.\nstep 0 | loss 1.4841 | psnr 4.22 | ssim 0.003                                   \nstep 10 | loss 1.6012 | psnr 3.86 | ssim 0.005                                  \nstep 20 | loss 0.9701 | psnr 7.49 | ssim 0.008                                  \nstep 30 | loss 1.3357 | psnr 5.01 | ssim 0.003                                  \nstep 40 | loss 1.2484 | psnr 5.27 | ssim 0.016                                  \nstep 50 | loss 1.1038 | psnr 6.32 | ssim 0.021                                  \nstep 60 | loss 1.2800 | psnr 5.19 | ssim 0.021                                  \nstep 70 | loss 1.0198 | psnr 6.84 | ssim 0.067                                  \nstep 80 | loss 0.7285 | psnr 8.89 | ssim 0.280                                  \nstep 90 | loss 0.7281 | psnr 8.76 | ssim 0.367                                  \nstep 100 | loss 0.5434 | psnr 11.26 | ssim 0.592                                \nEpoch 1/100:   5%|█▍                         | 106/2000 [00:25<07:00,  4.50it/s]^C\nTraceback (most recent call last):\n  File \"/kaggle/working/wave-vim-refinev3/train.py\", line 426, in <module>\n    main()\n  File \"/kaggle/working/wave-vim-refinev3/train.py\", line 301, in main\n    scaler.scale(total_loss).backward()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n    torch.autograd.backward(\n  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n    _engine_run_backward(\n  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nKeyboardInterrupt\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Train from check Points ","metadata":{}},{"cell_type":"code","source":"# PROJ = \"/kaggle/working/wave-vim-refinev3\"\n\n# %cd $PROJ\n# !python train.py --config ./configs/default.yaml --resume /kaggle/input/ckpt-i188ke94v3-cdd30/ckpt_i188ke94V3_cdd30.pt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:24:44.192766Z","iopub.execute_input":"2025-08-23T09:24:44.193142Z","iopub.status.idle":"2025-08-23T09:24:44.196958Z","shell.execute_reply.started":"2025-08-23T09:24:44.193093Z","shell.execute_reply":"2025-08-23T09:24:44.196272Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## MultiGPU Training","metadata":{}},{"cell_type":"code","source":"# PROJ = \"/kaggle/working/wave-vim-refinev3\"\n# !export NCCL_P2P_DISABLE=1\n# !torchrun --standalone --nproc_per_node=2 train.py --config ./configs/default.yaml --amp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:24:44.197789Z","iopub.execute_input":"2025-08-23T09:24:44.198243Z","iopub.status.idle":"2025-08-23T09:24:44.239051Z","shell.execute_reply.started":"2025-08-23T09:24:44.198225Z","shell.execute_reply":"2025-08-23T09:24:44.238329Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# %cd /kaggle/working/wave-vim-refinev3\n# %env NCCL_P2P_DISABLE=1\n# %env NCCL_IB_DISABLE=1\n# %env OMP_NUM_THREADS=1\n# # 2 GPUs on Kaggle\n# !torchrun --standalone --nproc_per_node=2 train.py --config ./configs/default.yaml --amp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:24:44.239744Z","iopub.execute_input":"2025-08-23T09:24:44.239975Z","iopub.status.idle":"2025-08-23T09:24:44.254385Z","shell.execute_reply.started":"2025-08-23T09:24:44.239955Z","shell.execute_reply":"2025-08-23T09:24:44.253755Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# !torchrun --standalone --nproc_per_node=2 train.py \\\n#     --config ./configs/default.yaml \\\n#     --resume /kaggle/working/outputs/dsm_wavevitmamba_tinyrefiner/ckpt_final.pt \\\n#     --amp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:24:44.255068Z","iopub.execute_input":"2025-08-23T09:24:44.255307Z","iopub.status.idle":"2025-08-23T09:24:44.269542Z","shell.execute_reply.started":"2025-08-23T09:24:44.255281Z","shell.execute_reply":"2025-08-23T09:24:44.268869Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# 3. Inference","metadata":{}},{"cell_type":"markdown","source":"## In-line Inference ","metadata":{}},{"cell_type":"code","source":"# # Eddit \n# import torch\n# from PIL import Image\n# import torchvision.transforms as T\n# import matplotlib.pyplot as plt\n# import matplotlib.image as mpimg\n# import yaml\n# import os\n\n# # from src.models.restorer import load_restorer\n# from src.infer_utils import load_restorer\n\n\n# # Device\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# # Load config\n# with open('./configs/default.yaml', 'r') as f:\n#     cfg = yaml.safe_load(f)\n\n# # Load checkpoint\n# # ckpt = '/kaggle/input/final-pt-with-25-5image-100epoch/ckpt_final.pt'\n# # ckpt = '/kaggle/input/ckpt-it150000-v2-e1-e95-cdd11-30/ckpt_it150000_V2_e1-e95-cdd11_30.pt'\n# # ckpt = '/kaggle/input/v1-cdd1183/ckpt_finalV1_cdd1183.pt'\n# ckpt = '/kaggle/working/outputs/dsm_wavevitmamba_tinyrefiner/ckpt_final.pt'\n# model = load_restorer(cfg, ckpt_path=ckpt, device=device)\n\n# # Input paths\n# img_path = '/kaggle/input/cdd-11-30/CDD-11_test/haze_rain/00018.png'\n# clear_path = '/kaggle/input/cdd-11-30/CDD-11_test/clear/00018.png'\n\n# # Output directory\n# output_dir = '/kaggle/working/outputs/'\n# os.makedirs(output_dir, exist_ok=True)\n\n# # Preprocessing\n# # to_t = T.Compose([T.Resize(cfg[\"val_data\"][\"size\"]), T.ToTensor()])\n# # im = Image.open(img_path).convert('RGB')\n# # x = to_t(im).unsqueeze(0).to(device)\n\n# to_t = T.ToTensor()  # no resize\n# im = Image.open(img_path).convert('RGB')\n# x = to_t(im).unsqueeze(0).to(device)  # keeps original H×W\n \n# print(\"PIL size (W,H):\", im.size)\n# print(\"Tensor x shape:\", tuple(x.shape))  # (1,3,H,W)\n\n# # Inference\n# model.eval()\n# with torch.no_grad():\n#     y = model.infer(x, text_prompt=None)\n\n# # Save restored image\n# out = y.clamp(0, 1).cpu().squeeze(0)\n# out_img = T.ToPILImage()(out)\n# restored_path = os.path.join(output_dir, 'ckpt_final.png')\n# out_img.save(restored_path)\n# print(f\"Restored image saved to {restored_path}\")\n\n# # Load images for visualization\n# degraded = mpimg.imread(img_path)\n# restored = mpimg.imread(restored_path)\n# clear = mpimg.imread(clear_path)\n\n# # Plot grid\n# fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n# axes[0].imshow(degraded); axes[0].set_title(\"Input: Degraded\"); axes[0].axis(\"off\")\n# axes[1].imshow(restored); axes[1].set_title(\"Output: Restored ckpt_final\"); axes[1].axis(\"off\")\n# axes[2].imshow(clear);    axes[2].set_title(\"Ground Truth\");    axes[2].axis(\"off\")\n# plt.tight_layout()\n\n# # Save grid\n# grid_path = os.path.join(output_dir, 'comparison_gridckpt_ckpt_final.png')\n# plt.savefig(grid_path, dpi=300, bbox_inches='tight')\n# print(f\"Comparison grid saved to {grid_path}\")\n\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:24:44.271792Z","iopub.execute_input":"2025-08-23T09:24:44.272013Z","iopub.status.idle":"2025-08-23T09:24:44.282704Z","shell.execute_reply.started":"2025-08-23T09:24:44.271996Z","shell.execute_reply":"2025-08-23T09:24:44.282119Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Models Comparison ","metadata":{}},{"cell_type":"code","source":"# !rm -rf /kaggle/working/outputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:24:44.283321Z","iopub.execute_input":"2025-08-23T09:24:44.283502Z","iopub.status.idle":"2025-08-23T09:24:44.297759Z","shell.execute_reply.started":"2025-08-23T09:24:44.283487Z","shell.execute_reply":"2025-08-23T09:24:44.297213Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# import torch\n# from PIL import Image\n# import torchvision.transforms as T\n# import matplotlib.pyplot as plt\n# import matplotlib.image as mpimg\n# import yaml\n# import os\n\n# # from src.models.restorer import load_restorer\n# from src.infer_utils import load_restorer\n\n\n# # Device\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# # Load config\n# with open('./configs/default.yaml', 'r') as f:\n#     cfg = yaml.safe_load(f)\n\n# # Models to compare (name, checkpoint path)\n# models_to_compare = [\n#     (\"Model 1 V1cdd30 \", \"/kaggle/input/v1-models/ckpt_finalV1cdd30.pt\"),\n#     (\"Model 2 V1cdd117\", \"/kaggle/input/v1-models/ckpt_finalV1cdd117.pt\"),\n#     (\"Model 3 V1cdd1183 \", \"/kaggle/input/v1-models/ckpt_finalV1cdd1183.pt\"),\n#     (\"Model 4 V2cdd30\", \"/kaggle/input/ckpt-finalv2cdd30/ckpt_finalV2cdd30.pt\"),\n    \n    \n\n# ]\n\n# # Input paths\n# img_path = '/kaggle/input/cdd-11-30/CDD-11_test/low_haze_rain/00010.png'\n# clear_path = '/kaggle/input/cdd-11-30/CDD-11_test/clear/00010.png'\n\n# # Output directory\n# output_dir = '/kaggle/working/outputs/'\n# os.makedirs(output_dir, exist_ok=True)\n\n# # Preprocessing\n# # to_t = T.Compose([T.Resize(cfg[\"val_data\"][\"size\"]), T.ToTensor()])\n# # im = Image.open(img_path).convert('RGB')\n# # x = to_t(im).unsqueeze(0).to(device)\n# to_t = T.ToTensor()  # no resize\n# im = Image.open(img_path).convert('RGB')\n# x = to_t(im).unsqueeze(0).to(device)  # keeps original H×W\n# print(\"PIL size (W,H):\", im.size)\n# print(\"Tensor x shape:\", tuple(x.shape))  # (1,3,H,W)\n\n\n# # Store results\n# degraded = mpimg.imread(img_path)\n# clear = mpimg.imread(clear_path)\n# restored_results = []\n\n# # Run inference for each model\n# for model_name, ckpt in models_to_compare:\n#     print(f\"Running inference with {model_name}...\")\n\n#     # Load model\n#     model = load_restorer(cfg, ckpt_path=ckpt, device=device)\n#     model.eval()\n\n#     # Inference\n#     with torch.no_grad():\n#         y = model.infer(x, text_prompt=None)\n\n#     # Save restored image\n#     out = y.clamp(0, 1).cpu().squeeze(0)\n#     out_img = T.ToPILImage()(out)\n#     restored_path = os.path.join(output_dir, f'{model_name.replace(\" \", \"_\")}.png')\n#     out_img.save(restored_path)\n\n#     # Load for plotting\n#     restored = mpimg.imread(restored_path)\n#     restored_results.append((model_name, restored))\n\n#     print(f\"{model_name} result saved at {restored_path}\")\n\n# # --- Plotting ---\n# n_models = len(models_to_compare)\n# fig, axes = plt.subplots(n_models, 3, figsize=(12, 4 * n_models))\n\n# if n_models == 1:  # Handle single model case\n#     axes = [axes]\n\n# for i, (model_name, restored) in enumerate(restored_results):\n#     axes[i][0].imshow(degraded)\n#     axes[i][0].set_title(\"Input: Degraded\")\n#     axes[i][0].axis(\"off\")\n\n#     axes[i][1].imshow(restored)\n#     axes[i][1].set_title(f\"Output: {model_name}\")\n#     axes[i][1].axis(\"off\")\n\n#     axes[i][2].imshow(clear)\n#     axes[i][2].set_title(\"Ground Truth\")\n#     axes[i][2].axis(\"off\")\n\n# plt.tight_layout()\n\n# # Save final comparison grid\n# grid_path = os.path.join(output_dir, 'comparison_all_models.png')\n# plt.savefig(grid_path, dpi=300, bbox_inches='tight')\n# print(f\"Comparison grid saved to {grid_path}\")\n\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:24:44.298480Z","iopub.execute_input":"2025-08-23T09:24:44.298701Z","iopub.status.idle":"2025-08-23T09:24:44.311303Z","shell.execute_reply.started":"2025-08-23T09:24:44.298680Z","shell.execute_reply":"2025-08-23T09:24:44.310675Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# import torch\n# from PIL import Image\n# import torchvision.transforms as T\n# import matplotlib.pyplot as plt\n# import matplotlib.image as mpimg\n# import yaml\n# import os\n# import numpy as np\n# from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n\n# from src.infer_utils import load_restorer\n\n# # -------------------------\n# # Device\n# # -------------------------\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# # -------------------------\n# # Load config\n# # -------------------------\n# with open('./configs/default.yaml', 'r') as f:\n#     cfg = yaml.safe_load(f)\n\n# # -------------------------\n# # Models to compare\n# # -------------------------\n# models_to_compare = [\n#     (\"Model 1 V1cdd30\", \"/kaggle/input/v1-models/ckpt_finalV1cdd30.pt\"),\n#     (\"Model 2 V1cdd117\", \"/kaggle/input/v1-models/ckpt_finalV1cdd117.pt\"),\n#     (\"Model 3 V1cdd1183\", \"/kaggle/input/v1-models/ckpt_finalV1cdd1183.pt\"),\n#     (\"Model 4 V2cdd30\", \"/kaggle/input/ckpt-finalv2cdd30/ckpt_finalV2cdd30.pt\"),\n# ]\n\n# # -------------------------\n# # Input paths\n# # -------------------------\n# img_path = '/kaggle/input/cdd-11-30/CDD-11_test/low_haze_rain/00010.png'\n# clear_path = '/kaggle/input/cdd-11-30/CDD-11_test/clear/00010.png'\n\n# # -------------------------\n# # Output directory\n# # -------------------------\n# output_dir = '/kaggle/working/outputs/'\n# os.makedirs(output_dir, exist_ok=True)\n\n# # -------------------------\n# # Preprocessing\n# # -------------------------\n# to_t = T.ToTensor()\n# im = Image.open(img_path).convert('RGB')\n# x = to_t(im).unsqueeze(0).to(device)\n\n# # Store results\n# degraded = mpimg.imread(img_path)\n# clear_np = np.array(Image.open(clear_path).convert('RGB')).astype(np.float32) / 255.0\n# restored_results = []\n\n# # -------------------------\n# # Run inference for each model\n# # -------------------------\n# for model_name, ckpt in models_to_compare:\n#     print(f\"Running inference with {model_name}...\")\n\n#     # Load model\n#     model = load_restorer(cfg, ckpt_path=ckpt, device=device)\n#     model.eval()\n\n#     with torch.no_grad():\n#         y = model.infer(x, text_prompt=None)\n\n#     # Convert tensor -> numpy in [0,1]\n#     restored_np = y.clamp(0, 1).cpu().squeeze(0).permute(1, 2, 0).numpy()\n\n#     # --- Clip or pad restored image to match clear image ---\n#     h_c, w_c, _ = clear_np.shape\n#     h_r, w_r, _ = restored_np.shape\n\n#     # Height\n#     if h_r > h_c:\n#         restored_np = restored_np[:h_c, :, :]\n#     elif h_r < h_c:\n#         pad_h = h_c - h_r\n#         restored_np = np.pad(restored_np, ((0, pad_h), (0,0), (0,0)), mode='edge')\n\n#     # Width\n#     if w_r > w_c:\n#         restored_np = restored_np[:, :w_c, :]\n#     elif w_r < w_c:\n#         pad_w = w_c - w_r\n#         restored_np = np.pad(restored_np, ((0,0), (0,pad_w), (0,0)), mode='edge')\n\n#     # Compute PSNR and SSIM\n#     psnr_val = psnr(clear_np, restored_np, data_range=1.0)\n#     ssim_val = ssim(clear_np, restored_np, channel_axis=-1, data_range=1.0)\n\n#     # Save restored image\n#     out_img = (restored_np * 255).astype(np.uint8)\n#     out_pil = Image.fromarray(out_img)\n#     restored_path = os.path.join(output_dir, f'{model_name.replace(\" \", \"_\")}.png')\n#     out_pil.save(restored_path)\n\n#     restored_results.append((model_name, restored_path, psnr_val, ssim_val))\n#     print(f\"{model_name}: PSNR={psnr_val:.2f}, SSIM={ssim_val:.4f}\")\n\n# # -------------------------\n# # Plotting comparison\n# # -------------------------\n# n_models = len(models_to_compare)\n# fig, axes = plt.subplots(n_models, 3, figsize=(12, 4 * n_models))\n\n# if n_models == 1:\n#     axes = [axes]\n\n# for i, (model_name, restored_path, psnr_val, ssim_val) in enumerate(restored_results):\n#     restored = mpimg.imread(restored_path)\n\n#     axes[i][0].imshow(degraded)\n#     axes[i][0].set_title(f\"Input: Degraded\", fontsize=10)\n#     axes[i][0].axis(\"off\")\n\n#     axes[i][1].imshow(restored)\n#     axes[i][1].set_title(f\"{model_name}\\nPSNR={psnr_val:.2f}, SSIM={ssim_val:.4f}\", fontsize=10)\n#     axes[i][1].axis(\"off\")\n\n#     axes[i][2].imshow(clear_np)\n#     axes[i][2].set_title(\"Ground Truth\", fontsize=10)\n#     axes[i][2].axis(\"off\")\n\n# plt.tight_layout()\n\n# grid_path = os.path.join(output_dir, 'comparison_all_models.png')\n# plt.savefig(grid_path, dpi=300, bbox_inches='tight')\n# print(f\"Comparison grid saved to {grid_path}\")\n\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:24:44.312034Z","iopub.execute_input":"2025-08-23T09:24:44.312215Z","iopub.status.idle":"2025-08-23T09:24:44.327245Z","shell.execute_reply.started":"2025-08-23T09:24:44.312195Z","shell.execute_reply":"2025-08-23T09:24:44.326563Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"# !set -e\n# %cd /kaggle/working/wave-vim-refinev3\n\n# !python /kaggle/working/wave-vim-refinev3/evaluate_cdd.py \\\n#   --config ./configs/default.yaml \\\n#   --ckpt /kaggle/input/v1-models/ckpt_finalV1cdd30.pt \\\n#   --gt_clear_dir /kaggle/input/cdd-11/CDD-11_test/clear \\\n#   --deg_dir      /kaggle/input/cdd-11/CDD-11_test/haze\\\n#   --size 256 256 \\\n#   --mode run-model \\\n#   --tag low \\\n#   --csv_out  /kaggle/working/eval/model_evaluation_result.csv \\\n#   --json_out /kaggle/working/eval/model_evaluation_result.json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:24:44.328068Z","iopub.execute_input":"2025-08-23T09:24:44.328292Z","iopub.status.idle":"2025-08-23T09:24:44.342300Z","shell.execute_reply.started":"2025-08-23T09:24:44.328268Z","shell.execute_reply":"2025-08-23T09:24:44.341564Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# import os\n# import subprocess\n# import pandas as pd\n# import json\n\n# # Paths\n# base_dir = \"/kaggle/working/wave-vim-refinev3\"\n# config = os.path.join(base_dir, \"configs/default.yaml\")\n# gt_dir = \"/kaggle/input/cdd-11/CDD-11_test/clear\"\n\n# # Degradation types to test\n# deg_dirs = [\n#     \"/kaggle/input/cdd-11-30/CDD-11_test/haze\",\n#     \"/kaggle/input/cdd-11-30/CDD-11_test/rain\",\n#     \"/kaggle/input/cdd-11-30/CDD-11_test/low\",\n#     \"/kaggle/input/cdd-11-30/CDD-11_test/low_haze_rain\",\n#     \"/kaggle/input/cdd-11-30/CDD-11_test/haze_snow\",\n#     \"/kaggle/input/cdd-11-30/CDD-11_test/haze_rain\",\n# ]  \n\n# # Model checkpoints to test\n# model_ckpts = [\n#     \"/kaggle/input/v1-models/ckpt_finalV1cdd30.pt\",\n#     \"/kaggle/input/v1-models/ckpt_finalV1cdd117.pt\",\n#     \"/kaggle/input/v1-models/ckpt_finalV1cdd1183.pt\",\n#     \"/kaggle/input/ckpt-finalv2cdd30/ckpt_finalV2cdd30.pt\",\n# ]\n\n# # Output folder\n# out_dir = \"/kaggle/working/eval\"\n# os.makedirs(out_dir, exist_ok=True)\n\n# # Store all results for merging\n# all_csvs = []\n# all_jsons = []\n\n# for ckpt in model_ckpts:\n#     model_name = os.path.splitext(os.path.basename(ckpt))[0]\n#     for deg in deg_dirs:\n#         deg_name = os.path.basename(deg)\n        \n#         csv_out = os.path.join(out_dir, f\"{model_name}_{deg_name}.csv\")\n#         json_out = os.path.join(out_dir, f\"{model_name}_{deg_name}.json\")\n        \n#         print(f\"Running evaluation: {model_name} on {deg_name}\")\n        \n#         subprocess.run([\n#             \"python\", os.path.join(base_dir, \"evaluate_cdd.py\"),\n#             \"--config\", config,\n#             \"--ckpt\", ckpt,\n#             \"--gt_clear_dir\", gt_dir,\n#             \"--deg_dir\", deg,\n#             \"--size\", \"256\", \"256\",\n#             \"--mode\", \"run-model\",\n#             \"--tag\", deg_name,\n#             \"--csv_out\", csv_out,\n#             \"--json_out\", json_out\n#         ], check=True)\n        \n#         all_csvs.append((model_name, deg_name, csv_out))\n#         all_jsons.append((model_name, deg_name, json_out))\n\n# # === Merge CSVs ===\n# dfs = []\n# for model_name, deg_name, path in all_csvs:\n#     df = pd.read_csv(path)\n#     df[\"model\"] = model_name\n#     df[\"degradation\"] = deg_name\n#     dfs.append(df)\n\n# merged_df = pd.concat(dfs, ignore_index=True)\n# merged_csv = os.path.join(out_dir, \"all_models_results.csv\")\n# merged_df.to_csv(merged_csv, index=False)\n# print(f\"Merged CSV saved to {merged_csv}\")\n\n# # === Merge JSONs ===\n# merged_results = []\n# for model_name, deg_name, path in all_jsons:\n#     with open(path, \"r\") as f:\n#         data = json.load(f)\n#     data[\"model\"] = model_name\n#     data[\"degradation\"] = deg_name\n#     merged_results.append(data)\n\n# merged_json = os.path.join(out_dir, \"all_models_results.json\")\n# with open(merged_json, \"w\") as f:\n#     json.dump(merged_results, f, indent=2)\n# print(f\"Merged JSON saved to {merged_json}\")\n\n# # === Create Summary ===\n# # Select only numeric metric columns (exclude strings like filenames)\n# numeric_df = merged_df.select_dtypes(include=[\"number\"])\n# metric_cols = numeric_df.columns.tolist()\n\n# # Average per model + degradation\n# summary_model_deg = merged_df.groupby([\"model\", \"degradation\"])[metric_cols].mean().reset_index()\n\n# # Average per model across all degradations\n# summary_model = merged_df.groupby(\"model\")[metric_cols].mean().reset_index()\n# summary_model[\"degradation\"] = \"ALL\"\n\n# # Combine both\n# summary_df = pd.concat([summary_model_deg, summary_model], ignore_index=True)\n\n# # Save to Excel with two sheets\n# summary_xlsx = os.path.join(out_dir, \"all_models_results.xlsx\")\n# with pd.ExcelWriter(summary_xlsx) as writer:\n#     merged_df.to_excel(writer, sheet_name=\"Raw Results\", index=False)\n#     summary_df.to_excel(writer, sheet_name=\"Summary\", index=False)\n\n# print(f\"Summary Excel saved to {summary_xlsx}\")\n\n# # === Show Summary in Notebook Output ===\n# print(\"\\nSummary of Model Performance:\")\n# display(summary_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:24:44.343151Z","iopub.execute_input":"2025-08-23T09:24:44.343343Z","iopub.status.idle":"2025-08-23T09:24:44.354475Z","shell.execute_reply.started":"2025-08-23T09:24:44.343316Z","shell.execute_reply":"2025-08-23T09:24:44.353810Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# !rm -rf /kaggle/working/eval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:24:44.355083Z","iopub.execute_input":"2025-08-23T09:24:44.355281Z","iopub.status.idle":"2025-08-23T09:24:44.368733Z","shell.execute_reply.started":"2025-08-23T09:24:44.355266Z","shell.execute_reply":"2025-08-23T09:24:44.368074Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"","metadata":{}}]}